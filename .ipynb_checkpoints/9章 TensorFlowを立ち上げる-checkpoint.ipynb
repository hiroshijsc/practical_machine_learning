{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最初のグラフの作成とセッション内での実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name = \"x\")\n",
    "y = tf.Variable(4, name = \"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グラフの管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype = tf.float32, name = \"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.6959320e+01]\n",
      " [ 4.3698898e-01]\n",
      " [ 9.4245886e-03]\n",
      " [-1.0791138e-01]\n",
      " [ 6.4842808e-01]\n",
      " [-3.9986235e-06]\n",
      " [-3.7866351e-03]\n",
      " [-4.2142656e-01]\n",
      " [-4.3467718e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 10.206464\n",
      "Epoch 100 MSE= 0.6961687\n",
      "Epoch 200 MSE= 0.5341018\n",
      "Epoch 300 MSE= 0.52983874\n",
      "Epoch 400 MSE= 0.5286645\n",
      "Epoch 500 MSE= 0.5277859\n",
      "Epoch 600 MSE= 0.52709734\n",
      "Epoch 700 MSE= 0.5265545\n",
      "Epoch 800 MSE= 0.5261245\n",
      "Epoch 900 MSE= 0.5257821\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradient = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradient)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE=\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 8.215597\n",
      "Epoch 100 MSE= 0.6414855\n",
      "Epoch 200 MSE= 0.5532764\n",
      "Epoch 300 MSE= 0.5448658\n",
      "Epoch 400 MSE= 0.53970575\n",
      "Epoch 500 MSE= 0.53590924\n",
      "Epoch 600 MSE= 0.53308976\n",
      "Epoch 700 MSE= 0.5309876\n",
      "Epoch 800 MSE= 0.5294143\n",
      "Epoch 900 MSE= 0.5282321\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]#mseの勾配を計算し、thetaに代入している\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE=\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 12.802074\n",
      "Epoch 100 MSE= 0.90899915\n",
      "Epoch 200 MSE= 0.6605843\n",
      "Epoch 300 MSE= 0.6217614\n",
      "Epoch 400 MSE= 0.59676373\n",
      "Epoch 500 MSE= 0.5784827\n",
      "Epoch 600 MSE= 0.5649842\n",
      "Epoch 700 MSE= 0.5549819\n",
      "Epoch 800 MSE= 0.5475454\n",
      "Epoch 900 MSE= 0.5419964\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE=\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 11.125973\n",
      "Epoch 100 MSE= 0.55621946\n",
      "Epoch 200 MSE= 0.5283321\n",
      "Epoch 300 MSE= 0.52485114\n",
      "Epoch 400 MSE= 0.5243915\n",
      "Epoch 500 MSE= 0.52433044\n",
      "Epoch 600 MSE= 0.5243222\n",
      "Epoch 700 MSE= 0.5243212\n",
      "Epoch 800 MSE= 0.524321\n",
      "Epoch 900 MSE= 0.524321\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE=\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(tf.float32, shape = (None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A:[[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A:[[4, 5, 6], [7, 8, 9]]})\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n + 1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = \"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5559, 17183, 19661, 15152, 12488,  1794, 15363, 13323,   840,\n",
       "        1717, 13136, 15213,  7774,  6443,  5075, 20038,  3253,  6663,\n",
       "       19166,  8426,   493, 12563, 14609,  7000,  2106,  1970, 13466,\n",
       "        5946, 17939, 15898,  9661, 10886, 12302,  8675,  4205,  9790,\n",
       "        4568, 15416, 14242, 20527,  3768, 11200, 14706,  7493,  4502,\n",
       "       18305, 16710, 15503, 18004, 10028, 11904,  8307,  3349,  9133,\n",
       "        5244, 16325, 17517,  8468, 14940, 18447,  8942, 11181,  9180,\n",
       "       14564, 17399, 11369,  7955,  6983,  2323, 10322,    88,  3967,\n",
       "       13214, 20180,  3364,  8280, 10858,  7215, 19949, 13940,  6277,\n",
       "       15811,   312, 13159, 12728, 13115,  3799,  3026, 10949,   868,\n",
       "        8265, 19797,  1292,  5833,  4173, 18317, 11634, 16245,  5763,\n",
       "        1122])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(m, size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, time 0.07s\n",
      "epoch:100, time 0.06s\n",
      "epoch:200, time 0.06s\n",
      "epoch:300, time 0.06s\n",
      "epoch:400, time 0.06s\n",
      "epoch:500, time 0.06s\n",
      "epoch:600, time 0.06s\n",
      "epoch:700, time 0.06s\n",
      "epoch:800, time 0.06s\n",
      "epoch:900, time 0.06s\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict = {X:X_batch, y:y_batch})\n",
    "        process_time =  time.time() - start\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"epoch:{}, time {:.2f}s\".format(epoch, process_time))\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの保存と復元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name = \"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()#構築フェーズの終わりにsaverノードを作成\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "            \n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hiroshi/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name = \"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "saver = tf.train.Saver()#構築フェーズの終わりにsaverノードを作成\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.import_meta_graph(\"/tmp/my_model_final.ckpt.meta\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    \n",
    "    sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoardを使ったグラフと訓練曲線の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100, 9) for Tensor 'X:0', which has shape '(?, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-251b6e030cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (100, 9) for Tensor 'X:0', which has shape '(?, 3)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()                                                     # not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名前スコープ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュール性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = \"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
    "b1 = tf.Variable(0.0, name = \"bias1\")\n",
    "b2 = tf.Variable(0.0, name = \"bias2\")\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name = \"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w1), b2, name = \"z2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu1 = tf.maximum(z1, 0., name = \"relu1\")\n",
    "relu2 = tf.maximum(z2, 0., name = \"relu2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.add(relu1, relu2, name = \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name = \"weights\")\n",
    "    b = tf.Variable(0.0, name = \"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name = \"z\")\n",
    "    return tf.maximum(z, 0., name = \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = \"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name = \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name = \"weights\")\n",
    "        b = tf.Variable(0.0, name = \"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name = \"z\")\n",
    "        return tf.maximum(z, 0., name = \"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 変数の共有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X, threshold):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name = \"weights\")\n",
    "        b = tf.Variable(0.0, name = \"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name = \"z\")\n",
    "    return tf.maximum(z, threshold, name = \"max\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = tf.Variable(0.0, name = \"threshold\")\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = \"X\")\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name = \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        if not hasattr(relu, \"threshold\"):\n",
    "            relu.threshold = tf.Variable(0.0, name = \"threshold\")\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name = \"weights\")\n",
    "        b = tf.Variable(0.0, name = \"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name = \"z\")\n",
    "    return tf.maximum(z, 0., name = \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape = (), initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習問題12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_moons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons_with_bias = np.c_[np.ones((m, 1)), X_moons]\n",
    "y_moons_column_vector = y_moons.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(m * test_ratio)\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_moon_batch(X_train, y_train, batch_size):\n",
    "    rnd_indice = np.random.choice(len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indice]\n",
    "    y_batch = y_train[rnd_indice]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = fetch_moon_batch(X_train, y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hiroshi/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:514: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch: 0 \tLoss_val: 0.79260236\n",
      "Epoch: 100 \tLoss_val: 0.34346348\n",
      "Epoch: 200 \tLoss_val: 0.3075404\n",
      "Epoch: 300 \tLoss_val: 0.29288894\n",
      "Epoch: 400 \tLoss_val: 0.28533572\n",
      "Epoch: 500 \tLoss_val: 0.28047803\n",
      "Epoch: 600 \tLoss_val: 0.27808294\n",
      "Epoch: 700 \tLoss_val: 0.27615443\n",
      "Epoch: 800 \tLoss_val: 0.27551997\n",
      "Epoch: 900 \tLoss_val: 0.27491233\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "logits = tf.matmul(X, theta, name = \"logits\")\n",
    "y_proba = tf.sigmoid(logits)\n",
    "loss = tf.losses.log_loss(y, y_proba)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "loss_validation = []\n",
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_moon_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test, y: y_test})\n",
    "        loss_validation.append(loss_val)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss_val:\", loss_val)\n",
    "            \n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0, 1000, 1000), loss_validation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enhanced = np.c_[X_train,\n",
    "                         np.square(X_train[:, 1]),\n",
    "                         np.square(X_train[:, 2]),\n",
    "                         X_train[:, 1] ** 3,\n",
    "                         X_train[:, 2] ** 3]\n",
    "X_test_enhanced = np.c_[X_test,\n",
    "                        np.square(X_test[:, 1]),\n",
    "                        np.square(X_test[:, 2]),\n",
    "                        X_test[:, 1] ** 3,\n",
    "                        X_test[:, 2] ** 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss_val: 0.62998503\n",
      "Epoch: 100 \tLoss_val: 0.28031063\n",
      "Epoch: 200 \tLoss_val: 0.22422491\n",
      "Epoch: 300 \tLoss_val: 0.19513626\n",
      "Epoch: 400 \tLoss_val: 0.17578289\n",
      "Epoch: 500 \tLoss_val: 0.16122366\n",
      "Epoch: 600 \tLoss_val: 0.14969102\n",
      "Epoch: 700 \tLoss_val: 0.1401069\n",
      "Epoch: 800 \tLoss_val: 0.13199675\n",
      "Epoch: 900 \tLoss_val: 0.12510939\n",
      "Epoch: 1000 \tLoss_val: 0.1190321\n",
      "Epoch: 1100 \tLoss_val: 0.113660105\n",
      "Epoch: 1200 \tLoss_val: 0.10890315\n",
      "Epoch: 1300 \tLoss_val: 0.10462557\n",
      "Epoch: 1400 \tLoss_val: 0.10080933\n",
      "Epoch: 1500 \tLoss_val: 0.097329214\n",
      "Epoch: 1600 \tLoss_val: 0.094126016\n",
      "Epoch: 1700 \tLoss_val: 0.09120082\n",
      "Epoch: 1800 \tLoss_val: 0.08848128\n",
      "Epoch: 1900 \tLoss_val: 0.08601011\n",
      "Epoch: 2000 \tLoss_val: 0.08369793\n",
      "Epoch: 2100 \tLoss_val: 0.08153568\n",
      "Epoch: 2200 \tLoss_val: 0.07956797\n",
      "Epoch: 2300 \tLoss_val: 0.07772261\n",
      "Epoch: 2400 \tLoss_val: 0.0760151\n",
      "Epoch: 2500 \tLoss_val: 0.07437582\n",
      "Epoch: 2600 \tLoss_val: 0.072814636\n",
      "Epoch: 2700 \tLoss_val: 0.07136773\n",
      "Epoch: 2800 \tLoss_val: 0.070009165\n",
      "Epoch: 2900 \tLoss_val: 0.06874217\n",
      "Epoch: 3000 \tLoss_val: 0.06750215\n",
      "Epoch: 3100 \tLoss_val: 0.066351205\n",
      "Epoch: 3200 \tLoss_val: 0.065243624\n",
      "Epoch: 3300 \tLoss_val: 0.064185396\n",
      "Epoch: 3400 \tLoss_val: 0.06317465\n",
      "Epoch: 3500 \tLoss_val: 0.062206898\n",
      "Epoch: 3600 \tLoss_val: 0.06129834\n",
      "Epoch: 3700 \tLoss_val: 0.0604152\n",
      "Epoch: 3800 \tLoss_val: 0.05958738\n",
      "Epoch: 3900 \tLoss_val: 0.058780123\n",
      "Epoch: 4000 \tLoss_val: 0.058026787\n",
      "Epoch: 4100 \tLoss_val: 0.057269074\n",
      "Epoch: 4200 \tLoss_val: 0.056573987\n",
      "Epoch: 4300 \tLoss_val: 0.05587842\n",
      "Epoch: 4400 \tLoss_val: 0.055199653\n",
      "Epoch: 4500 \tLoss_val: 0.05456297\n",
      "Epoch: 4600 \tLoss_val: 0.053959\n",
      "Epoch: 4700 \tLoss_val: 0.053370997\n",
      "Epoch: 4800 \tLoss_val: 0.05280205\n",
      "Epoch: 4900 \tLoss_val: 0.05224736\n",
      "Epoch: 5000 \tLoss_val: 0.051708277\n",
      "Epoch: 5100 \tLoss_val: 0.051175565\n",
      "Epoch: 5200 \tLoss_val: 0.050676018\n",
      "Epoch: 5300 \tLoss_val: 0.050183762\n",
      "Epoch: 5400 \tLoss_val: 0.049690176\n",
      "Epoch: 5500 \tLoss_val: 0.04923773\n",
      "Epoch: 5600 \tLoss_val: 0.04879737\n",
      "Epoch: 5700 \tLoss_val: 0.048368778\n",
      "Epoch: 5800 \tLoss_val: 0.047965452\n",
      "Epoch: 5900 \tLoss_val: 0.047545556\n",
      "Epoch: 6000 \tLoss_val: 0.047167283\n",
      "Epoch: 6100 \tLoss_val: 0.046795826\n",
      "Epoch: 6200 \tLoss_val: 0.046428703\n",
      "Epoch: 6300 \tLoss_val: 0.046077132\n",
      "Epoch: 6400 \tLoss_val: 0.045716725\n",
      "Epoch: 6500 \tLoss_val: 0.045376644\n",
      "Epoch: 6600 \tLoss_val: 0.0450428\n",
      "Epoch: 6700 \tLoss_val: 0.044729613\n",
      "Epoch: 6800 \tLoss_val: 0.04440357\n",
      "Epoch: 6900 \tLoss_val: 0.04409076\n",
      "Epoch: 7000 \tLoss_val: 0.04381875\n",
      "Epoch: 7100 \tLoss_val: 0.04349895\n",
      "Epoch: 7200 \tLoss_val: 0.043222714\n",
      "Epoch: 7300 \tLoss_val: 0.042926706\n",
      "Epoch: 7400 \tLoss_val: 0.042645764\n",
      "Epoch: 7500 \tLoss_val: 0.042374235\n",
      "Epoch: 7600 \tLoss_val: 0.042112485\n",
      "Epoch: 7700 \tLoss_val: 0.04184761\n",
      "Epoch: 7800 \tLoss_val: 0.041598205\n",
      "Epoch: 7900 \tLoss_val: 0.041330256\n",
      "Epoch: 8000 \tLoss_val: 0.041089173\n",
      "Epoch: 8100 \tLoss_val: 0.04083269\n",
      "Epoch: 8200 \tLoss_val: 0.040609736\n",
      "Epoch: 8300 \tLoss_val: 0.040411144\n",
      "Epoch: 8400 \tLoss_val: 0.040185846\n",
      "Epoch: 8500 \tLoss_val: 0.039970923\n",
      "Epoch: 8600 \tLoss_val: 0.03974717\n",
      "Epoch: 8700 \tLoss_val: 0.039535657\n",
      "Epoch: 8800 \tLoss_val: 0.03932259\n",
      "Epoch: 8900 \tLoss_val: 0.03913901\n",
      "Epoch: 9000 \tLoss_val: 0.038920265\n",
      "Epoch: 9100 \tLoss_val: 0.038737692\n",
      "Epoch: 9200 \tLoss_val: 0.038554456\n",
      "Epoch: 9300 \tLoss_val: 0.038350657\n",
      "Epoch: 9400 \tLoss_val: 0.0381653\n",
      "Epoch: 9500 \tLoss_val: 0.038010757\n",
      "Epoch: 9600 \tLoss_val: 0.037807673\n",
      "Epoch: 9700 \tLoss_val: 0.037627973\n",
      "Epoch: 9800 \tLoss_val: 0.037457213\n",
      "Epoch: 9900 \tLoss_val: 0.037311465\n",
      "Epoch: 10000 \tLoss_val: 0.037155706\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 6\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "logits = tf.matmul(X, theta, name = \"logits\")\n",
    "y_proba = tf.sigmoid(logits)\n",
    "loss = tf.losses.log_loss(y, y_proba)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "loss_validation = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_moon_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test_enhanced, y: y_test})\n",
    "        loss_validation.append(loss_val)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss_val:\", loss_val)\n",
    "            save_path = saver.save(sess, \"/tmp/logreg_model.ckpt\")\n",
    "            \n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    save_path = saver.save(sess, \"/tmp/logreg_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/logreg_model.ckpt\n",
      "Epoch: 0\tLoss_val:0.022104\tTime:0.00min\n",
      "Epoch: 1000\tLoss_val:0.021900\tTime:0.47min\n",
      "Epoch: 2000\tLoss_val:0.021696\tTime:0.97min\n",
      "Epoch: 3000\tLoss_val:0.021606\tTime:1.40min\n",
      "Epoch: 4000\tLoss_val:0.021471\tTime:1.69min\n",
      "Epoch: 5000\tLoss_val:0.021285\tTime:1.96min\n",
      "Epoch: 6000\tLoss_val:0.021121\tTime:2.23min\n",
      "Epoch: 7000\tLoss_val:0.021025\tTime:2.67min\n",
      "Epoch: 8000\tLoss_val:0.020880\tTime:3.16min\n",
      "Epoch: 9000\tLoss_val:0.020763\tTime:3.62min\n",
      "Epoch: 10000\tLoss_val:0.020660\tTime:4.11min\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 6\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "logits = tf.matmul(X, theta, name = \"logits\")\n",
    "y_proba = tf.sigmoid(logits)\n",
    "loss = tf.losses.log_loss(y, y_proba)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/logreg_model.ckpt\")\n",
    "    start = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_moon_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test_enhanced, y: y_test})\n",
    "        loss_validation.append(loss_val)\n",
    "        \n",
    "        if epoch % 1000 == 0:\n",
    "            process_min_time = (time.time() - start) / 60\n",
    "            print(\"Epoch: {}\\tLoss_val:{:.6f}\\tTime:{:.2f} min\".format(epoch, loss_val, process_min_time))\n",
    "            save_path = saver.save(sess, \"/tmp/logreg_model.ckpt\")\n",
    "            \n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    save_path = saver.save(sess, \"/tmp/logreg_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, initializer=None, seed=42, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform([n_inputs_including_bias, 1], -1.0, 1.0, seed=seed)\n",
    "            theta = tf.Variable(initializer, name=\"theta\")\n",
    "            logits = tf.matmul(X, theta, name=\"logits\")\n",
    "            y_proba = tf.sigmoid(logits)\n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss = tf.losses.log_loss(y, y_proba, scope=\"loss\")\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "    return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_logreg_model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "\n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
